[ 2025-02-07 09:57:06,368 ] 23 root - INFO - Initialized Data Ingestion with config: <customer_churn.entity.config_entity.DataIngestionConfig object at 0x000001BF095E25D0>
[ 2025-02-07 09:57:06,368 ] 16 root - INFO - Initiate the data ingestion
[ 2025-02-07 09:57:06,368 ] 107 root - INFO - Starting data ingestion process...
[ 2025-02-07 09:57:06,368 ] 109 root - INFO - Fetching data from MongoDB...
[ 2025-02-07 09:57:06,368 ] 32 root - INFO - Connecting to MongoDB...
[ 2025-02-07 09:57:07,121 ] 38 root - INFO - Fetching data from MongoDB: Database = UDAYML, Collection = CustomerChurn
[ 2025-02-07 09:57:12,729 ] 45 root - INFO - Dropping '_id' column from DataFrame
[ 2025-02-07 09:57:12,776 ] 49 root - INFO - Exported 7043 rows from MongoDB successfully.
[ 2025-02-07 09:57:12,776 ] 112 root - INFO - Saving raw data to feature store...
[ 2025-02-07 09:57:12,776 ] 62 root - INFO - Creating feature store directory: Artifacts\02_07_2025_09_57_03\data_ingestion\feature_store\Telecome_Churn_Data
[ 2025-02-07 09:57:12,776 ] 65 root - INFO - Saving raw data to feature store at: Artifacts\02_07_2025_09_57_03\data_ingestion\feature_store\Telecome_Churn_Data/WA_Fn-UseC_-Telco-Customer-Churn.csv
[ 2025-02-07 09:57:12,824 ] 68 root - INFO - Data successfully saved in feature store.
[ 2025-02-07 09:57:12,824 ] 115 root - INFO - Splitting data into train and test sets...
[ 2025-02-07 09:57:12,824 ] 78 root - INFO - Performing train-test split on the dataframe...
[ 2025-02-07 09:57:12,843 ] 82 root - INFO - Train-test split completed. Train size: 5634, Test size: 1409
[ 2025-02-07 09:57:12,843 ] 85 root - INFO - Creating directory for train/test files: Artifacts\02_07_2025_09_57_03\data_ingestion\data_ingestion
[ 2025-02-07 09:57:12,843 ] 88 root - INFO - Exporting train file to: Artifacts\02_07_2025_09_57_03\data_ingestion\data_ingestion\train.csv
[ 2025-02-07 09:57:12,890 ] 93 root - INFO - Exporting test file to: Artifacts\02_07_2025_09_57_03\data_ingestion\data_ingestion\test.csv
[ 2025-02-07 09:57:12,900 ] 98 root - INFO - Train and test files exported successfully.
[ 2025-02-07 09:57:12,902 ] 118 root - INFO - Creating DataIngestionArtifact...
[ 2025-02-07 09:57:12,902 ] 124 root - INFO - Data ingestion process completed successfully.
[ 2025-02-07 09:57:12,904 ] 18 root - INFO - Data Ingestion Completed
[ 2025-02-07 09:57:12,904 ] 14 root - INFO - Initializing DataValidation component.
[ 2025-02-07 09:57:12,904 ] 17 root - INFO - Reading schema configuration from: data_schema\schema.yaml
[ 2025-02-07 09:57:12,931 ] 19 root - INFO - Schema configuration loaded successfully.
[ 2025-02-07 09:57:12,931 ] 24 root - INFO - Initiate data validation
[ 2025-02-07 09:57:12,931 ] 130 root - INFO - Starting data validation process.
[ 2025-02-07 09:57:12,931 ] 27 root - INFO - Reading data from file: Artifacts\02_07_2025_09_57_03\data_ingestion\data_ingestion\train.csv
[ 2025-02-07 09:57:12,956 ] 27 root - INFO - Reading data from file: Artifacts\02_07_2025_09_57_03\data_ingestion\data_ingestion\test.csv
[ 2025-02-07 09:57:12,973 ] 133 root - INFO - Training and testing datasets loaded successfully.
[ 2025-02-07 09:57:12,973 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-07 09:57:12,973 ] 38 root - INFO - Column validation successful.
[ 2025-02-07 09:57:12,973 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-07 09:57:12,973 ] 38 root - INFO - Column validation successful.
[ 2025-02-07 09:57:12,973 ] 48 root - INFO - Validating missing values in the dataset.
[ 2025-02-07 09:57:12,991 ] 52 root - INFO - No missing values found.
[ 2025-02-07 09:57:12,991 ] 48 root - INFO - Validating missing values in the dataset.
[ 2025-02-07 09:57:12,993 ] 52 root - INFO - No missing values found.
[ 2025-02-07 09:57:12,993 ] 60 root - INFO - Validating uniqueness of customerID in the dataset.
[ 2025-02-07 09:57:12,995 ] 64 root - INFO - All customerID values are unique.
[ 2025-02-07 09:57:12,995 ] 72 root - INFO - Validating categorical values in the dataset.
[ 2025-02-07 09:57:13,002 ] 77 root - INFO - All categorical values are valid.
[ 2025-02-07 09:57:13,003 ] 148 root - INFO - Checking for dataset drift between training and testing datasets.
[ 2025-02-07 09:57:13,003 ] 101 root - INFO - Detecting dataset drift between base and current datasets.
[ 2025-02-07 09:57:13,395 ] 120 root - INFO - Saving drift report to: Artifacts\02_07_2025_09_57_03\data_validation\drift_report\report.yaml
[ 2025-02-07 09:57:13,422 ] 122 root - INFO - Dataset drift detection completed. Drift status: False
[ 2025-02-07 09:57:13,422 ] 152 root - INFO - Directory created for validated data: Artifacts\02_07_2025_09_57_03\data_validation\validated
[ 2025-02-07 09:57:13,422 ] 154 root - INFO - Saving validated training and testing datasets.
[ 2025-02-07 09:57:13,473 ] 157 root - INFO - Validated datasets saved successfully.
[ 2025-02-07 09:57:13,473 ] 26 root - INFO - Data Validation Completed
[ 2025-02-07 09:57:13,473 ] 29 root - INFO - data Transformation started
[ 2025-02-07 09:57:13,473 ] 24 root - INFO - Initializing DataTransformation class
[ 2025-02-07 09:57:13,473 ] 27 root - INFO - DataTransformation class initialized successfully
[ 2025-02-07 09:57:13,473 ] 100 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2025-02-07 09:57:13,473 ] 102 root - INFO - Starting data transformation process
[ 2025-02-07 09:57:13,473 ] 105 root - INFO - Reading training and testing data
[ 2025-02-07 09:57:13,473 ] 35 root - INFO - Reading data from file: Artifacts\02_07_2025_09_57_03\data_validation\validated\train.csv
[ 2025-02-07 09:57:13,506 ] 37 root - INFO - Data read successfully with shape: (5634, 21)
[ 2025-02-07 09:57:13,506 ] 40 root - INFO - Dropping 'customerID' column as it is irrelevant
[ 2025-02-07 09:57:13,506 ] 42 root - INFO - 'customerID' column dropped successfully
[ 2025-02-07 09:57:13,506 ] 45 root - INFO - Converting 'TotalCharges' column to numeric
[ 2025-02-07 09:57:13,506 ] 47 root - INFO - 'TotalCharges' column converted to numeric successfully
[ 2025-02-07 09:57:13,506 ] 50 root - INFO - Dropping rows where 'tenure' is 0
[ 2025-02-07 09:57:13,506 ] 52 root - INFO - Rows with 'tenure' == 0 dropped. Updated data shape: (5627, 20)
[ 2025-02-07 09:57:13,506 ] 35 root - INFO - Reading data from file: Artifacts\02_07_2025_09_57_03\data_validation\validated\test.csv
[ 2025-02-07 09:57:13,523 ] 37 root - INFO - Data read successfully with shape: (1409, 21)
[ 2025-02-07 09:57:13,523 ] 40 root - INFO - Dropping 'customerID' column as it is irrelevant
[ 2025-02-07 09:57:13,523 ] 42 root - INFO - 'customerID' column dropped successfully
[ 2025-02-07 09:57:13,523 ] 45 root - INFO - Converting 'TotalCharges' column to numeric
[ 2025-02-07 09:57:13,523 ] 47 root - INFO - 'TotalCharges' column converted to numeric successfully
[ 2025-02-07 09:57:13,523 ] 50 root - INFO - Dropping rows where 'tenure' is 0
[ 2025-02-07 09:57:13,523 ] 52 root - INFO - Rows with 'tenure' == 0 dropped. Updated data shape: (1405, 20)
[ 2025-02-07 09:57:13,523 ] 108 root - INFO - Training data shape: (5627, 20), Testing data shape: (1405, 20)
[ 2025-02-07 09:57:13,523 ] 111 root - INFO - Splitting input and target features
[ 2025-02-07 09:57:13,540 ] 117 root - INFO - Input and target features split successfully
[ 2025-02-07 09:57:13,540 ] 120 root - INFO - Getting the preprocessor object
[ 2025-02-07 09:57:13,540 ] 60 root - INFO - Entered get_data_transformer_object method of DataTransformation class
[ 2025-02-07 09:57:13,540 ] 70 root - INFO - Identified numerical features: ['tenure', 'MonthlyCharges', 'TotalCharges']
[ 2025-02-07 09:57:13,540 ] 71 root - INFO - Identified categorical features: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']
[ 2025-02-07 09:57:13,540 ] 78 root - INFO - Numerical pipeline created with KNNImputer and StandardScaler
[ 2025-02-07 09:57:13,540 ] 84 root - INFO - Categorical pipeline created with OneHotEncoder
[ 2025-02-07 09:57:13,540 ] 91 root - INFO - ColumnTransformer created with numerical and categorical pipelines
[ 2025-02-07 09:57:13,540 ] 93 root - INFO - Exiting get_data_transformer_object method of DataTransformation class
[ 2025-02-07 09:57:13,582 ] 123 root - INFO - Preprocessor object fitted successfully
[ 2025-02-07 09:57:13,582 ] 126 root - INFO - Transforming input features
[ 2025-02-07 09:57:13,623 ] 129 root - INFO - Input features transformed successfully
[ 2025-02-07 09:57:13,623 ] 132 root - INFO - Combining transformed features with target features
[ 2025-02-07 09:57:13,623 ] 135 root - INFO - Transformed data combined with target features
[ 2025-02-07 09:57:13,623 ] 138 root - INFO - Saving transformed data
[ 2025-02-07 09:57:13,623 ] 141 root - INFO - Transformed data saved successfully
[ 2025-02-07 09:57:13,623 ] 144 root - INFO - Saving preprocessor object
[ 2025-02-07 09:57:13,623 ] 48 root - INFO - Entered the save_object method of MainUtils class
[ 2025-02-07 09:57:13,623 ] 52 root - INFO - Exited the save_object method of MainUtils class
[ 2025-02-07 09:57:13,623 ] 48 root - INFO - Entered the save_object method of MainUtils class
[ 2025-02-07 09:57:13,623 ] 52 root - INFO - Exited the save_object method of MainUtils class
[ 2025-02-07 09:57:13,623 ] 147 root - INFO - Preprocessor object saved successfully
[ 2025-02-07 09:57:13,623 ] 150 root - INFO - Preparing DataTransformationArtifact
[ 2025-02-07 09:57:13,623 ] 156 root - INFO - DataTransformationArtifact prepared successfully
[ 2025-02-07 09:57:13,623 ] 158 root - INFO - Exiting initiate_data_transformation method of DataTransformation class
[ 2025-02-07 09:57:13,623 ] 33 root - INFO - data Transformation completed
