[ 2025-02-10 21:06:33,214 ] 23 root - INFO - Initialized Data Ingestion with config: <customer_churn.entity.config_entity.DataIngestionConfig object at 0x000001DE193AEF90>
[ 2025-02-10 21:06:33,214 ] 18 root - INFO - Initiate the data ingestion
[ 2025-02-10 21:06:33,214 ] 105 root - INFO - Starting data ingestion process...
[ 2025-02-10 21:06:33,214 ] 107 root - INFO - Fetching data from MongoDB...
[ 2025-02-10 21:06:33,214 ] 32 root - INFO - Connecting to MongoDB...
[ 2025-02-10 21:06:33,667 ] 38 root - INFO - Fetching data from MongoDB: Database = UDAYML, Collection = CustomerChurn
[ 2025-02-10 21:06:35,298 ] 45 root - INFO - Dropping '_id' column from DataFrame
[ 2025-02-10 21:06:35,342 ] 110 root - INFO - Saving raw data to feature store...
[ 2025-02-10 21:06:35,344 ] 60 root - INFO - Creating feature store directory: Artifacts\02_10_2025_21_06_26\data_ingestion\feature_store\Telecome_Churn_Data
[ 2025-02-10 21:06:35,344 ] 63 root - INFO - Saving raw data to feature store at: Artifacts\02_10_2025_21_06_26\data_ingestion\feature_store\Telecome_Churn_Data/WA_Fn-UseC_-Telco-Customer-Churn.csv
[ 2025-02-10 21:06:35,394 ] 66 root - INFO - Data successfully saved in feature store.
[ 2025-02-10 21:06:35,394 ] 113 root - INFO - Splitting data into train and test sets...
[ 2025-02-10 21:06:35,394 ] 76 root - INFO - Performing train-test split on the dataframe...
[ 2025-02-10 21:06:35,394 ] 80 root - INFO - Train-test split completed. Train size: 5634, Test size: 1409
[ 2025-02-10 21:06:35,394 ] 83 root - INFO - Creating directory for train/test files: Artifacts\02_10_2025_21_06_26\data_ingestion\data_ingestion
[ 2025-02-10 21:06:35,394 ] 86 root - INFO - Exporting train file to: Artifacts\02_10_2025_21_06_26\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:06:35,442 ] 91 root - INFO - Exporting test file to: Artifacts\02_10_2025_21_06_26\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:06:35,458 ] 96 root - INFO - Train and test files exported successfully.
[ 2025-02-10 21:06:35,474 ] 116 root - INFO - Creating DataIngestionArtifact...
[ 2025-02-10 21:06:35,474 ] 122 root - INFO - Data ingestion process completed successfully.
[ 2025-02-10 21:06:35,474 ] 20 root - INFO - Data Ingestion Completed
[ 2025-02-10 21:06:35,474 ] 14 root - INFO - Initializing DataValidation component.
[ 2025-02-10 21:06:35,474 ] 17 root - INFO - Reading schema configuration from: data_schema\schema.yaml
[ 2025-02-10 21:06:35,493 ] 19 root - INFO - Schema configuration loaded successfully.
[ 2025-02-10 21:06:35,493 ] 26 root - INFO - Initiate data validation
[ 2025-02-10 21:06:35,493 ] 130 root - INFO - Starting data validation process.
[ 2025-02-10 21:06:35,493 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_06_26\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:06:35,534 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_06_26\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:06:35,554 ] 133 root - INFO - Training and testing datasets loaded successfully.
[ 2025-02-10 21:06:35,554 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:06:35,554 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:06:35,554 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:06:35,554 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:06:35,554 ] 60 root - INFO - Validating uniqueness of customerID in the dataset.
[ 2025-02-10 21:06:35,555 ] 64 root - INFO - All customerID values are unique.
[ 2025-02-10 21:06:35,555 ] 72 root - INFO - Validating categorical values in the dataset.
[ 2025-02-10 21:06:35,564 ] 77 root - INFO - All categorical values are valid.
[ 2025-02-10 21:06:35,564 ] 148 root - INFO - Checking for dataset drift between training and testing datasets.
[ 2025-02-10 21:06:35,564 ] 101 root - INFO - Detecting dataset drift between base and current datasets.
[ 2025-02-10 21:06:35,988 ] 120 root - INFO - Saving drift report to: Artifacts\02_10_2025_21_06_26\data_validation\drift_report\report.yaml
[ 2025-02-10 21:06:35,994 ] 122 root - INFO - Dataset drift detection completed. Drift status: False
[ 2025-02-10 21:06:35,994 ] 152 root - INFO - Directory created for validated data: Artifacts\02_10_2025_21_06_26\data_validation\validated
[ 2025-02-10 21:06:35,995 ] 154 root - INFO - Saving validated training and testing datasets.
[ 2025-02-10 21:06:36,053 ] 157 root - INFO - Validated datasets saved successfully.
[ 2025-02-10 21:06:36,053 ] 28 root - INFO - Data Validation Completed
[ 2025-02-10 21:06:36,053 ] 31 root - INFO - data Transformation started
[ 2025-02-10 21:06:36,053 ] 55 root - INFO - Initializing DataTransformation class
[ 2025-02-10 21:06:36,053 ] 58 root - INFO - DataTransformation class initialized successfully
[ 2025-02-10 21:06:36,053 ] 124 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2025-02-10 21:06:36,053 ] 126 root - INFO - Starting data transformation process
[ 2025-02-10 21:06:36,053 ] 129 root - INFO - Reading training and testing data
[ 2025-02-10 21:06:36,132 ] 132 root - INFO - Training data shape: (5634, 21), Testing data shape: (1409, 21)
[ 2025-02-10 21:06:36,132 ] 135 root - INFO - Splitting input and target features
[ 2025-02-10 21:06:36,142 ] 141 root - INFO - Input and target features split successfully
[ 2025-02-10 21:06:36,142 ] 144 root - INFO - Getting the preprocessor object
[ 2025-02-10 21:06:36,142 ] 75 root - INFO - Entered get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:06:36,142 ] 85 root - INFO - Identified numerical features: ['tenure', 'MonthlyCharges', 'TotalCharges']
[ 2025-02-10 21:06:36,142 ] 86 root - INFO - Identified categorical features: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']
[ 2025-02-10 21:06:36,142 ] 99 root - INFO - Numerical pipeline created with KNNImputer and StandardScaler
[ 2025-02-10 21:06:36,142 ] 105 root - INFO - Categorical pipeline created with OneHotEncoder
[ 2025-02-10 21:06:36,143 ] 114 root - INFO - ColumnTransformer created with custom preprocessor, numerical, and categorical pipelines
[ 2025-02-10 21:06:36,143 ] 116 root - INFO - Exiting get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:06:36,148 ] 33 root - INFO - Replacing blank spaces in 'TotalCharges' with NaN
[ 2025-02-10 21:06:36,152 ] 36 root - INFO - TotalCharges column after replacing blanks: ['2607.6' '3735.45' '522.95' ... '3829.75' '8033.1' '609.65']
[ 2025-02-10 21:06:36,152 ] 39 root - INFO - Converting 'TotalCharges' column to numeric
[ 2025-02-10 21:06:36,156 ] 43 root - INFO - Dropping rows where 'tenure' is 0
[ 2025-02-10 21:06:36,157 ] 46 root - INFO - Preprocessing completed. Updated data shape: (5624, 2)
[ 2025-02-10 21:06:36,160 ] 191 root - ERROR - Error in initiate_data_transformation method: could not convert string to float: ' '
