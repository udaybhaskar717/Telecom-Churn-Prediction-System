[ 2025-02-10 21:02:38,364 ] 23 root - INFO - Initialized Data Ingestion with config: <customer_churn.entity.config_entity.DataIngestionConfig object at 0x00000287E61E7DA0>
[ 2025-02-10 21:02:38,364 ] 18 root - INFO - Initiate the data ingestion
[ 2025-02-10 21:02:38,364 ] 108 root - INFO - Starting data ingestion process...
[ 2025-02-10 21:02:38,364 ] 110 root - INFO - Fetching data from MongoDB...
[ 2025-02-10 21:02:38,364 ] 32 root - INFO - Connecting to MongoDB...
[ 2025-02-10 21:02:38,831 ] 38 root - INFO - Fetching data from MongoDB: Database = UDAYML, Collection = CustomerChurn
[ 2025-02-10 21:02:43,179 ] 45 root - INFO - Dropping '_id' column from DataFrame
[ 2025-02-10 21:02:43,188 ] 47 root - INFO - Exported 7043 rows from MongoDB successfully.
[ 2025-02-10 21:02:43,192 ] 113 root - INFO - Saving raw data to feature store...
[ 2025-02-10 21:02:43,192 ] 63 root - INFO - Creating feature store directory: Artifacts\02_10_2025_21_02_31\data_ingestion\feature_store\Telecome_Churn_Data
[ 2025-02-10 21:02:43,193 ] 66 root - INFO - Saving raw data to feature store at: Artifacts\02_10_2025_21_02_31\data_ingestion\feature_store\Telecome_Churn_Data/WA_Fn-UseC_-Telco-Customer-Churn.csv
[ 2025-02-10 21:02:43,248 ] 69 root - INFO - Data successfully saved in feature store.
[ 2025-02-10 21:02:43,248 ] 116 root - INFO - Splitting data into train and test sets...
[ 2025-02-10 21:02:43,248 ] 79 root - INFO - Performing train-test split on the dataframe...
[ 2025-02-10 21:02:43,260 ] 83 root - INFO - Train-test split completed. Train size: 5634, Test size: 1409
[ 2025-02-10 21:02:43,260 ] 86 root - INFO - Creating directory for train/test files: Artifacts\02_10_2025_21_02_31\data_ingestion\data_ingestion
[ 2025-02-10 21:02:43,260 ] 89 root - INFO - Exporting train file to: Artifacts\02_10_2025_21_02_31\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:02:43,311 ] 94 root - INFO - Exporting test file to: Artifacts\02_10_2025_21_02_31\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:02:43,311 ] 99 root - INFO - Train and test files exported successfully.
[ 2025-02-10 21:02:43,327 ] 119 root - INFO - Creating DataIngestionArtifact...
[ 2025-02-10 21:02:43,327 ] 125 root - INFO - Data ingestion process completed successfully.
[ 2025-02-10 21:02:43,333 ] 20 root - INFO - Data Ingestion Completed
[ 2025-02-10 21:02:43,335 ] 14 root - INFO - Initializing DataValidation component.
[ 2025-02-10 21:02:43,335 ] 17 root - INFO - Reading schema configuration from: data_schema\schema.yaml
[ 2025-02-10 21:02:43,345 ] 19 root - INFO - Schema configuration loaded successfully.
[ 2025-02-10 21:02:43,345 ] 26 root - INFO - Initiate data validation
[ 2025-02-10 21:02:43,345 ] 130 root - INFO - Starting data validation process.
[ 2025-02-10 21:02:43,345 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_02_31\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:02:43,388 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_02_31\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:02:43,419 ] 133 root - INFO - Training and testing datasets loaded successfully.
[ 2025-02-10 21:02:43,420 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:02:43,420 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:02:43,420 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:02:43,420 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:02:43,420 ] 60 root - INFO - Validating uniqueness of customerID in the dataset.
[ 2025-02-10 21:02:43,423 ] 64 root - INFO - All customerID values are unique.
[ 2025-02-10 21:02:43,423 ] 72 root - INFO - Validating categorical values in the dataset.
[ 2025-02-10 21:02:43,435 ] 77 root - INFO - All categorical values are valid.
[ 2025-02-10 21:02:43,435 ] 148 root - INFO - Checking for dataset drift between training and testing datasets.
[ 2025-02-10 21:02:43,435 ] 101 root - INFO - Detecting dataset drift between base and current datasets.
[ 2025-02-10 21:02:43,767 ] 120 root - INFO - Saving drift report to: Artifacts\02_10_2025_21_02_31\data_validation\drift_report\report.yaml
[ 2025-02-10 21:02:43,781 ] 122 root - INFO - Dataset drift detection completed. Drift status: False
[ 2025-02-10 21:02:43,781 ] 152 root - INFO - Directory created for validated data: Artifacts\02_10_2025_21_02_31\data_validation\validated
[ 2025-02-10 21:02:43,781 ] 154 root - INFO - Saving validated training and testing datasets.
[ 2025-02-10 21:02:43,863 ] 157 root - INFO - Validated datasets saved successfully.
[ 2025-02-10 21:02:43,865 ] 28 root - INFO - Data Validation Completed
[ 2025-02-10 21:02:43,865 ] 31 root - INFO - data Transformation started
[ 2025-02-10 21:02:43,865 ] 55 root - INFO - Initializing DataTransformation class
[ 2025-02-10 21:02:43,865 ] 58 root - INFO - DataTransformation class initialized successfully
[ 2025-02-10 21:02:43,865 ] 124 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2025-02-10 21:02:43,865 ] 126 root - INFO - Starting data transformation process
[ 2025-02-10 21:02:43,865 ] 129 root - INFO - Reading training and testing data
[ 2025-02-10 21:02:43,938 ] 132 root - INFO - Training data shape: (5634, 21), Testing data shape: (1409, 21)
[ 2025-02-10 21:02:43,938 ] 135 root - INFO - Splitting input and target features
[ 2025-02-10 21:02:43,960 ] 141 root - INFO - Input and target features split successfully
[ 2025-02-10 21:02:43,960 ] 144 root - INFO - Getting the preprocessor object
[ 2025-02-10 21:02:43,960 ] 75 root - INFO - Entered get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:02:43,960 ] 85 root - INFO - Identified numerical features: ['tenure', 'MonthlyCharges', 'TotalCharges']
[ 2025-02-10 21:02:43,960 ] 86 root - INFO - Identified categorical features: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']
[ 2025-02-10 21:02:43,960 ] 99 root - INFO - Numerical pipeline created with KNNImputer and StandardScaler
[ 2025-02-10 21:02:43,960 ] 105 root - INFO - Categorical pipeline created with OneHotEncoder
[ 2025-02-10 21:02:43,960 ] 114 root - INFO - ColumnTransformer created with custom preprocessor, numerical, and categorical pipelines
[ 2025-02-10 21:02:43,960 ] 116 root - INFO - Exiting get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:02:43,971 ] 33 root - INFO - Replacing blank spaces in 'TotalCharges' with NaN
[ 2025-02-10 21:02:43,976 ] 36 root - INFO - TotalCharges column after replacing blanks: [  47.5  1170.55  504.05 ...  505.95  387.7  2647.1 ]
[ 2025-02-10 21:02:43,976 ] 39 root - INFO - Converting 'TotalCharges' column to numeric
[ 2025-02-10 21:02:43,976 ] 43 root - INFO - Dropping rows where 'tenure' is 0
[ 2025-02-10 21:02:43,977 ] 46 root - INFO - Preprocessing completed. Updated data shape: (5626, 2)
[ 2025-02-10 21:02:44,105 ] 191 root - ERROR - Error in initiate_data_transformation method: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 5626 and the array at index 1 has size 5634
