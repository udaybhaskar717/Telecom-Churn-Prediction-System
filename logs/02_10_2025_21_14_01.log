[ 2025-02-10 21:14:14,368 ] 23 root - INFO - Initialized Data Ingestion with config: <customer_churn.entity.config_entity.DataIngestionConfig object at 0x0000028B75641400>
[ 2025-02-10 21:14:14,368 ] 18 root - INFO - Initiate the data ingestion
[ 2025-02-10 21:14:14,369 ] 105 root - INFO - Starting data ingestion process...
[ 2025-02-10 21:14:14,369 ] 107 root - INFO - Fetching data from MongoDB...
[ 2025-02-10 21:14:14,369 ] 32 root - INFO - Connecting to MongoDB...
[ 2025-02-10 21:14:14,868 ] 38 root - INFO - Fetching data from MongoDB: Database = UDAYML, Collection = CustomerChurn
[ 2025-02-10 21:14:20,404 ] 45 root - INFO - Dropping '_id' column from DataFrame
[ 2025-02-10 21:14:20,444 ] 110 root - INFO - Saving raw data to feature store...
[ 2025-02-10 21:14:20,445 ] 60 root - INFO - Creating feature store directory: Artifacts\02_10_2025_21_14_01\data_ingestion\feature_store\Telecome_Churn_Data
[ 2025-02-10 21:14:20,446 ] 63 root - INFO - Saving raw data to feature store at: Artifacts\02_10_2025_21_14_01\data_ingestion\feature_store\Telecome_Churn_Data/WA_Fn-UseC_-Telco-Customer-Churn.csv
[ 2025-02-10 21:14:20,501 ] 66 root - INFO - Data successfully saved in feature store.
[ 2025-02-10 21:14:20,502 ] 113 root - INFO - Splitting data into train and test sets...
[ 2025-02-10 21:14:20,502 ] 76 root - INFO - Performing train-test split on the dataframe...
[ 2025-02-10 21:14:20,507 ] 80 root - INFO - Train-test split completed. Train size: 5634, Test size: 1409
[ 2025-02-10 21:14:20,508 ] 83 root - INFO - Creating directory for train/test files: Artifacts\02_10_2025_21_14_01\data_ingestion\data_ingestion
[ 2025-02-10 21:14:20,508 ] 86 root - INFO - Exporting train file to: Artifacts\02_10_2025_21_14_01\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:14:20,548 ] 91 root - INFO - Exporting test file to: Artifacts\02_10_2025_21_14_01\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:14:20,559 ] 96 root - INFO - Train and test files exported successfully.
[ 2025-02-10 21:14:20,562 ] 116 root - INFO - Creating DataIngestionArtifact...
[ 2025-02-10 21:14:20,562 ] 122 root - INFO - Data ingestion process completed successfully.
[ 2025-02-10 21:14:20,568 ] 20 root - INFO - Data Ingestion Completed
[ 2025-02-10 21:14:20,569 ] 14 root - INFO - Initializing DataValidation component.
[ 2025-02-10 21:14:20,570 ] 17 root - INFO - Reading schema configuration from: data_schema\schema.yaml
[ 2025-02-10 21:14:20,579 ] 19 root - INFO - Schema configuration loaded successfully.
[ 2025-02-10 21:14:20,579 ] 26 root - INFO - Initiate data validation
[ 2025-02-10 21:14:20,579 ] 130 root - INFO - Starting data validation process.
[ 2025-02-10 21:14:20,579 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_14_01\data_ingestion\data_ingestion\train.csv
[ 2025-02-10 21:14:20,618 ] 27 root - INFO - Reading data from file: Artifacts\02_10_2025_21_14_01\data_ingestion\data_ingestion\test.csv
[ 2025-02-10 21:14:20,636 ] 133 root - INFO - Training and testing datasets loaded successfully.
[ 2025-02-10 21:14:20,637 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:14:20,637 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:14:20,637 ] 35 root - INFO - Validating number of columns in the dataset.
[ 2025-02-10 21:14:20,637 ] 38 root - INFO - Column validation successful.
[ 2025-02-10 21:14:20,637 ] 60 root - INFO - Validating uniqueness of customerID in the dataset.
[ 2025-02-10 21:14:20,638 ] 64 root - INFO - All customerID values are unique.
[ 2025-02-10 21:14:20,638 ] 72 root - INFO - Validating categorical values in the dataset.
[ 2025-02-10 21:14:20,643 ] 77 root - INFO - All categorical values are valid.
[ 2025-02-10 21:14:20,643 ] 148 root - INFO - Checking for dataset drift between training and testing datasets.
[ 2025-02-10 21:14:20,643 ] 101 root - INFO - Detecting dataset drift between base and current datasets.
[ 2025-02-10 21:14:20,901 ] 120 root - INFO - Saving drift report to: Artifacts\02_10_2025_21_14_01\data_validation\drift_report\report.yaml
[ 2025-02-10 21:14:20,905 ] 122 root - INFO - Dataset drift detection completed. Drift status: True
[ 2025-02-10 21:14:20,906 ] 152 root - INFO - Directory created for validated data: Artifacts\02_10_2025_21_14_01\data_validation\validated
[ 2025-02-10 21:14:20,906 ] 154 root - INFO - Saving validated training and testing datasets.
[ 2025-02-10 21:14:20,956 ] 157 root - INFO - Validated datasets saved successfully.
[ 2025-02-10 21:14:20,957 ] 28 root - INFO - Data Validation Completed
[ 2025-02-10 21:14:20,957 ] 31 root - INFO - data Transformation started
[ 2025-02-10 21:14:20,957 ] 25 root - INFO - Initializing DataTransformation class
[ 2025-02-10 21:14:20,958 ] 28 root - INFO - DataTransformation class initialized successfully
[ 2025-02-10 21:14:20,958 ] 96 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2025-02-10 21:14:20,958 ] 98 root - INFO - Starting data transformation process
[ 2025-02-10 21:14:20,958 ] 101 root - INFO - Reading training and testing data
[ 2025-02-10 21:14:21,009 ] 104 root - INFO - Training data shape: (5634, 21), Testing data shape: (1409, 21)
[ 2025-02-10 21:14:21,009 ] 107 root - INFO - Splitting input and target features
[ 2025-02-10 21:14:21,016 ] 113 root - INFO - Input and target features split successfully
[ 2025-02-10 21:14:21,016 ] 116 root - INFO - Getting the preprocessor object
[ 2025-02-10 21:14:21,016 ] 52 root - INFO - Entered get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:14:21,016 ] 62 root - INFO - Identified numerical features: ['tenure', 'MonthlyCharges', 'TotalCharges']
[ 2025-02-10 21:14:21,016 ] 63 root - INFO - Identified categorical features: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']
[ 2025-02-10 21:14:21,016 ] 70 root - INFO - Numerical pipeline created with KNNImputer and StandardScaler
[ 2025-02-10 21:14:21,016 ] 76 root - INFO - Categorical pipeline created with OneHotEncoder
[ 2025-02-10 21:14:21,016 ] 86 root - INFO - ColumnTransformer created with custom preprocessor, numerical, and categorical pipelines
[ 2025-02-10 21:14:21,016 ] 88 root - INFO - Exiting get_data_transformer_object method of DataTransformation class
[ 2025-02-10 21:14:21,022 ] 163 root - ERROR - Error in initiate_data_transformation method: could not convert string to float: ' '
